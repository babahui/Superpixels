{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from vggNet import *\n",
    "from FCN import *\n",
    "\n",
    "\n",
    "def vgg(img_folder):\n",
    "    # specify gpu id\n",
    "    gpu_id = 0\n",
    "\n",
    "    model = vgg16(pretrained=True)\n",
    "    model.eval()\n",
    "    model.cuda(gpu_id)\n",
    "\n",
    "    img_path = img_folder\n",
    "    image = cv2.imread(img_path)\n",
    "    h, w, ch = image.shape\n",
    "\n",
    "    # 对图像内容计算\n",
    "    input1 = image.transpose((2, 0, 1))\n",
    "    input1 = np.float32(input1) / 255.0\n",
    "    input1 = np.reshape(input1, [1, ch, h, w])\n",
    "    input1 = torch.from_numpy(input1)\n",
    "    input1 = input1.cuda(gpu_id)\n",
    "\n",
    "    conv_1, conv_2 = model(input1)\n",
    "    conv_1 = conv_1.data.cpu().numpy()\n",
    "    conv_2 = conv_2.data.cpu().numpy()\n",
    "    \n",
    "    feat1 = np.zeros((h, w))\n",
    "    feat2 = np.zeros((h, w))\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            feat1[i, j] = np.mean(conv_1[0, :, i, j])\n",
    "            feat2[i, j] = np.mean(conv_2[0, :, i, j])\n",
    "            \n",
    "    return feat1, feat2\n",
    "\n",
    "\n",
    "def fcn(img_folder):\n",
    "    img_path = img_folder\n",
    "    image = cv2.imread(img_path)\n",
    "    h, w, ch = image.shape\n",
    "    n_class = 20\n",
    "    batch_size = 10\n",
    "\n",
    "    # 对图像内容计算\n",
    "    input = image.transpose((2, 0, 1))\n",
    "    input = np.float32(input) / 255.0\n",
    "    input = np.reshape(input, [1, ch, h, w])\n",
    "    input = torch.from_numpy(input)\n",
    "    # input = input.cuda(gpu_id)\n",
    "\n",
    "    vgg_model = VGGNet(requires_grad=True)\n",
    "    fcn_model = FCNs(pretrained_net=vgg_model, n_class=n_class)\n",
    "    output, output_2, output_3 = fcn_model(input)\n",
    "    \n",
    "    out = output.data.numpy()\n",
    "    out_2 = output_2.data.numpy()\n",
    "    out_3 = output_3.data.numpy()\n",
    "\n",
    "    h = h - 1\n",
    "    w = w - 1\n",
    "    feat = np.zeros((h, w))\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            feat[i, j] = np.mean(out[0, :, i, j])\n",
    "    \n",
    "    h = out_2.shape[2]\n",
    "    w = out_2.shape[3]    \n",
    "    out2 = np.zeros((h, w))\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            out2[i, j] = np.mean(out_2[0, :, i, j])\n",
    "      \n",
    "    h = out_3.shape[2]\n",
    "    w = out_3.shape[3]    \n",
    "    out3 = np.zeros((h, w))\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            out3[i, j] = np.mean(out_3[0, :, i, j])\n",
    "            \n",
    "    return feat, out2, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 80)\n",
      "graph success\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import skimage\n",
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed, mark_boundaries, find_boundaries\n",
    "from skimage.filters import sobel\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from os.path import basename, join, isfile\n",
    "import os\n",
    "import matplotlib.pyplot as plt    \n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from image_segmentation import normal_image_segmentation\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "basename = os.getcwd()\n",
    "img_dir = join(basename, 'input')\n",
    "img_list = [join(img_dir, f) for f in os.listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "\n",
    "def sp_met(img_path, met='watershed', sp_show=True, feat_show=True):\n",
    "    \n",
    "    # VGG feat\n",
    "    #  get conv feature\n",
    "#     img = cv2.imread(img_path)\n",
    "#     conv_1, conv_2 = vgg(img_path)\n",
    "#     conv_1_2 = (conv_1 + conv_2) / 2\n",
    "\n",
    "#     gray_img = skimage.io.imread(img_path, as_gray=True)\n",
    "#     comb = (gray_img + conv_1_2) / 2\n",
    "\n",
    "#     # FCN \n",
    "    #  get conv feature\n",
    "    feat, out2, out3 = fcn(img_path)\n",
    "    return out2, out3\n",
    "\n",
    "\n",
    "#     if feat_show == True:\n",
    "#         # vis feature\n",
    "#         fig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "#         ax[0, 0].imshow(img)\n",
    "#         ax[0, 0].set_title('ori-img')\n",
    "\n",
    "#         ax[0, 1].imshow(conv_1)\n",
    "#         ax[0, 1].set_title('vgg conv_1 feat')\n",
    "\n",
    "#         ax[1, 0].imshow(conv_2)\n",
    "#         ax[1, 0].set_title('vgg conv_2 feat')\n",
    "\n",
    "#         ax[1, 1].imshow(conv_1_2)\n",
    "#         ax[1, 1].set_title('vgg conv (1+2) feat')\n",
    "    \n",
    "        \n",
    "#         fig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "#         ax[0, 0].imshow(img)\n",
    "#         ax[0, 0].set_title('ori-img')\n",
    "\n",
    "#         ax[0, 1].imshow(conv_1, cmap='gray')\n",
    "#         ax[0, 1].set_title('vgg conv_1 feat')\n",
    "\n",
    "#         ax[1, 0].imshow(conv_2, cmap='gray')\n",
    "#         ax[1, 0].set_title('vgg conv_2 feat')\n",
    "\n",
    "#         ax[1, 1].imshow(conv_1_2, cmap='gray')\n",
    "#         ax[1, 1].set_title('vgg conv (1+2) feat')\n",
    "        \n",
    "        \n",
    "#         fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "#         ax[0, 0].imshow(img)\n",
    "#         ax[0, 0].set_title('ori-img')\n",
    "\n",
    "#         ax[0, 1].imshow(feat, cmap='gray')\n",
    "#         ax[0, 1].set_title('fcn feat')\n",
    "\n",
    "#         ax[1, 0].imshow(out2, cmap='gray')\n",
    "#         ax[1, 0].set_title('')\n",
    "\n",
    "#         ax[1, 1].imshow(out3, cmap='gray')\n",
    "#         ax[1, 1].set_title('')\n",
    "        \n",
    "#         plt.show()\n",
    "        \n",
    "#     # generate superpixels\n",
    "#     if met == 'felzenszwalb':\n",
    "#         # 1. use rgb\n",
    "#         segments_rgb = felzenszwalb(img, scale=100, sigma=0.5, min_size=50)\n",
    "#         # 2. use vgg16 conv_1, conv_2, conv_1_2\n",
    "#         segments_conv_1 = felzenszwalb(conv_1, scale=100, sigma=0.5, min_size=50)\n",
    "#         segments_conv_2 = felzenszwalb(conv_2, scale=100, sigma=0.5, min_size=50)\n",
    "#         segments_conv_1_2 = felzenszwalb(conv_1_2, scale=100, sigma=0.5, min_size=50)\n",
    "#         # 3. combined?\n",
    "#         segments_comb = felzenszwalb(comb, scale=100, sigma=0.5, min_size=50)\n",
    "\n",
    "        \n",
    "#     elif met == 'slic':\n",
    "#         # 1. use img\n",
    "#         segments_rgb = slic(img, n_segments=250, compactness=10, sigma=1)\n",
    "#         # 2. use feat_1, feat_2, feat_1_2\n",
    "#         segments_conv_1 = slic(conv_1, n_segments=50, compactness=10, sigma=1)\n",
    "#         segments_conv_2 = slic(conv_2, n_segments=25, compactness=10, sigma=1)\n",
    "#         segments_conv_1_2 = slic(conv_1_2, n_segments=9, compactness=10, sigma=1)\n",
    "#         # 3. combined?\n",
    "#         segments_comb = slic(comb, n_segments=250, compactness=10, sigma=1)\n",
    "\n",
    "        \n",
    "#     elif met == 'quickshift':\n",
    "        \n",
    "#         # 1. use img\n",
    "#         segments_rgb = quickshift(img, kernel_size=3, max_dist=6, ratio=0.5)\n",
    "#         # 2. use feat_1, feat_2, feat_1_2\n",
    "#         segments_conv_1 = quickshift(conv_1, kernel_size=3, max_dist=6, ratio=0.5)\n",
    "#         segments_conv_2 = quickshift(conv_2, kernel_size=3, max_dist=6, ratio=0.5)\n",
    "#         segments_conv_1_2 = quickshift(conv_1_2, kernel_size=3, max_dist=6, ratio=0.5)\n",
    "#         # 3. combined?\n",
    "#         segments_comb = quickshift(comb, kernel_size=3, max_dist=6, ratio=0.5)\n",
    "        \n",
    "        \n",
    "#     elif met == 'watershed':\n",
    "\n",
    "#         # 1. use img\n",
    "#         gradient = sobel(rgb2gray(img))\n",
    "#         segments_rgb = watershed(gradient, markers=250, compactness=0.001)\n",
    "#         # 2. use feat_1, feat_2, feat_1_2\n",
    "#         gradient = sobel(conv_1)\n",
    "#         segments_conv_1 = watershed(gradient, markers=250, compactness=0.001)\n",
    "        \n",
    "#         gradient = sobel(conv_2)\n",
    "#         segments_conv_2 = watershed(gradient, markers=250, compactness=0.001)\n",
    "        \n",
    "#         gradient = sobel(conv_1_2)\n",
    "#         segments_conv_1_2 = watershed(gradient, markers=250, compactness=0.001)\n",
    "        \n",
    "#         # 3. combined?\n",
    "#         gradient = sobel(comb)\n",
    "#         segments_comb = watershed(gradient, markers=250, compactness=0.001)\n",
    "        \n",
    "#     else:\n",
    "#         print('superpixels method need')\n",
    "        \n",
    "#     if sp_show == True:\n",
    "#         # show superpixels results\n",
    "#         fig, ax = plt.subplots(3, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "#         # superpixel vis\n",
    "#         ax[0, 0].imshow(img)\n",
    "#         ax[0, 0].set_title('ori-img')\n",
    "\n",
    "#         ax[0, 1].imshow(mark_boundaries(img, segments_conv_1))\n",
    "#         ax[0, 1].set_title('conv_1_feat')\n",
    "\n",
    "#         ax[1, 0].imshow(mark_boundaries(img, segments_conv_2))\n",
    "#         ax[1, 0].set_title('conv_2_feat')\n",
    "\n",
    "#         ax[1, 1].imshow(mark_boundaries(img, segments_conv_1_2))\n",
    "#         ax[1, 1].set_title('conv_1_2_feat')\n",
    "\n",
    "#         ax[2, 0].imshow(mark_boundaries(img, segments_rgb))\n",
    "#         ax[2, 0].set_title('rgb_feat')\n",
    "\n",
    "#         ax[2, 1].imshow(mark_boundaries(img, segments_comb))\n",
    "#         ax[2, 1].set_title('comb_feat')\n",
    "#         plt.show()\n",
    "\n",
    "        \n",
    "# vis part\n",
    "for img_path in img_list:\n",
    "    \n",
    "    if img_path[-3:] == 'jpg':\n",
    "#         out2, out3 = sp_met(img_path=img_path)\n",
    "        feat, out2, out3 = fcn(img_path)\n",
    "#         print(out2.shape)\n",
    "#         print(out3.shape)\n",
    "        \n",
    "#         for k in [2, 5, 8]:\n",
    "        # add our method\n",
    "        segments = normal_image_segmentation(m_img=out2, graph_met='syn_met', num_cuts=2)\n",
    "    #         plt.figure()\n",
    "    #         plt.imshow(segments)\n",
    "    #         plt.show()\n",
    "\n",
    "\n",
    "        # plot segments in different paras\n",
    "        plt.figure()\n",
    "        bounder = find_boundaries(segments, mode='thick').astype(np.uint8)\n",
    "        plt.imshow(bounder, cmap='gray')\n",
    "\n",
    "    #         plt.figure()\n",
    "    #         plt.imshow(mark_boundaries(out3, segments))\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "#         # weight of rgb and conv feat \n",
    "#         weight = [0.01, 0.1, 1, 10, 100]\n",
    "#         fig, ax = plt.subplots(3, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "#         for i, w in enumerate(weight):\n",
    "#             comb = (w * gray_img + conv_1_2) / (w + 1)\n",
    "#             segments_comb = felzenszwalb(comb, scale=100, sigma=0.5, min_size=50)\n",
    "\n",
    "#             ax[int(i-i%2)/2, int(i%2)].imshow(mark_boundaries(img, segments_comb))\n",
    "# #             ax[int(i-i%2)/2, int(i%2)].set_title('Subplot n°{}' .format(i+1))\n",
    "\n",
    "#         fig.delaxes(ax[2, 1])\n",
    "#         plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add our method\n",
    "m_img = np.asarray([[1,2],[3,4]])\n",
    "len(m_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35049\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed, mark_boundaries\n",
    "from os.path import join, isfile\n",
    "import os\n",
    "import cv2\n",
    "from skimage.filters import sobel\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# ASA, BR evaluate\n",
    "\n",
    "# by different sp numbers(given different paras here)\n",
    "\n",
    "para_list = [0.1, 1, 10, 50, 100, 200]\n",
    "# para_list = [1, 2, 5, 8, 10]\n",
    "# para_list = [0.001, 0.005, 0.01]\n",
    "\n",
    "# gtseg_dir = '../SEAL/data/groundtruth'\n",
    "# label_dir = '../SEAL/data/output/500'\n",
    "\n",
    "basename = os.getcwd()\n",
    "img_dir = join(basename, 'input')\n",
    "img_list = [join(img_dir, f) for f in os.listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "\n",
    "img_dir = './output'\n",
    "# prepare output folders\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "\n",
    "\n",
    "label_dir = []\n",
    "for met in ['rgb', 'vgg_conv', 'vgg_comb', 'fcn_conv', 'fcn_comb']:\n",
    "    feat_dir = join(img_dir, met)\n",
    "    if not os.path.exists(feat_dir):\n",
    "        os.makedirs(feat_dir)\n",
    "\n",
    "    for para in para_list:\n",
    "        para_dir = os.path.join(feat_dir, str(para))\n",
    "        if not os.path.exists(para_dir):\n",
    "            os.makedirs(para_dir)\n",
    "\n",
    "        \n",
    "# save sp results\n",
    "for img_path in img_list:\n",
    "    if img_path[-3:] == 'jpg':\n",
    "        img_name = img_path.split('/')[-1].split('.')[0]\n",
    "        print(img_name)\n",
    "        \n",
    "        #  get feature: rgb, vgg_conv, vgg_comb, fcn_conv, fcn_comb\n",
    "        rgb = cv2.imread(img_path)\n",
    "        gray_img = skimage.io.imread(img_path, as_gray=True)\n",
    "\n",
    "        conv_1, conv_2 = vgg(img_path)\n",
    "        vgg_conv = (conv_1 + conv_2) / 2\n",
    "        vgg_comb = (gray_img + vgg_conv) / 2\n",
    "        \n",
    "#         fcn_conv = fcn(img_path)        \n",
    "#         fcn_comb = (gray_img + fcn_conv) / 2\n",
    "        \n",
    "        # 与图片最后一行与最后一列拼接（更好的方法？）        \n",
    "        conv_ = fcn(img_path)\n",
    "        fcn_conv = np.resize(conv_, (gray_img.shape))\n",
    "        fcn_comb = (gray_img + fcn_conv) / 2\n",
    "        \n",
    "        for para in para_list:\n",
    "            for feat, feat_dir in zip([rgb, vgg_conv, vgg_comb, fcn_conv, fcn_comb], \\\n",
    "                                      ['rgb', 'vgg_conv', 'vgg_comb', 'fcn_conv', 'fcn_comb']):         \n",
    "\n",
    "                # save segmnets labels as uint16 png files\n",
    "                segments = felzenszwalb(feat, scale=para, sigma=0.5, min_size=50)\n",
    "#                 segments = quickshift(feat, kernel_size=3, max_dist=para, ratio=0.5)\n",
    "#                 gradient = sobel(rgb2gray(feat))\n",
    "#                 segments = watershed(gradient, markers=250, compactness=para)\n",
    "        \n",
    "                output_fullpath = os.path.join('./output', feat_dir, str(para), img_name + '.png')\n",
    "                cv2.imwrite(output_fullpath, np.uint16(segments))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, '../SEAL/eval')\n",
    "from eval import evaluate\n",
    "import os\n",
    "import matplotlib.pyplot as plt    \n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "# compute asa, br\n",
    "# by rgb, conv, comb\n",
    "\n",
    "asa_list, br_list = [], []\n",
    "gtseg_dir = './groundtruth'\n",
    "\n",
    "for feat, feat_dir in zip([rgb, vgg_conv, vgg_comb, fcn_conv, fcn_comb], \\\n",
    "                          ['rgb', 'vgg_conv', 'vgg_comb', 'fcn_conv', 'fcn_comb']):       \n",
    "    feat_asa, feat_br = [], []\n",
    "    for para in para_list:\n",
    "\n",
    "        label_dir = os.path.join('./output', feat_dir, str(para))\n",
    "        asa, br = evaluate(gtseg_dir, label_dir)\n",
    "        feat_asa.append(asa) \n",
    "        feat_br.append(br)\n",
    "        \n",
    "    asa_list.append(feat_asa)\n",
    "    br_list.append(feat_br)\n",
    "    \n",
    "\n",
    "# plot asa & br curves\n",
    "labels = ['rgb', 'vgg_conv', 'vgg_comb', 'fcn_conv', 'fcn_comb']\n",
    "\n",
    "plt.figure('ASA')\n",
    "for asa_, label in zip(asa_list, labels):\n",
    "    plt.plot(para_list, asa_, label=label)\n",
    "    plt.scatter(para_list, asa_)\n",
    "\n",
    "plt.xlabel('superpixels para')\n",
    "plt.ylabel('ASA (Achievable Segmentation Accuracy)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.figure('BR')\n",
    "for br_, label in zip(br_list, labels):\n",
    "    plt.plot(para_list, br_, label=label)\n",
    "    plt.scatter(para_list, br_)\n",
    "\n",
    "plt.xlabel('superpixels para')\n",
    "plt.ylabel('BR (Boundary Recall)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, io, segmentation, color\n",
    "\n",
    "out = color.label2rgb(labels2, img, kind='avg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PAN]",
   "language": "python",
   "name": "conda-env-PAN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
