{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from vggNet import *\n",
    "from FCN import *\n",
    "\n",
    "\n",
    "def vgg(img_folder):\n",
    "    # specify gpu id\n",
    "    gpu_id = 0\n",
    "\n",
    "    model = vgg16(pretrained=True)\n",
    "    model.eval()\n",
    "    model.cuda(gpu_id)\n",
    "\n",
    "    img_path = img_folder\n",
    "    image = cv2.imread(img_path)\n",
    "    h, w, ch = image.shape\n",
    "\n",
    "    # 对图像内容计算\n",
    "    input1 = image.transpose((2, 0, 1))\n",
    "    input1 = np.float32(input1) / 255.0\n",
    "    input1 = np.reshape(input1, [1, ch, h, w])\n",
    "    input1 = torch.from_numpy(input1)\n",
    "    input1 = input1.cuda(gpu_id)\n",
    "\n",
    "    conv_1, conv_2 = model(input1)\n",
    "    conv_1 = conv_1.data.cpu().numpy()\n",
    "    conv_2 = conv_2.data.cpu().numpy()\n",
    "    \n",
    "    feat1 = np.zeros((h, w))\n",
    "    feat2 = np.zeros((h, w))\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            feat1[i, j] = np.mean(conv_1[0, :, i, j])\n",
    "            feat2[i, j] = np.mean(conv_2[0, :, i, j])\n",
    "            \n",
    "    return feat1, feat2\n",
    "\n",
    "\n",
    "def fcn(img_folder):\n",
    "    img_path = img_folder\n",
    "    image = cv2.imread(img_path)\n",
    "    h, w, ch = image.shape\n",
    "    n_class = 20\n",
    "    batch_size = 10\n",
    "\n",
    "    # 对图像内容计算\n",
    "    input = image.transpose((2, 0, 1))\n",
    "    input = np.float32(input) / 255.0\n",
    "    input = np.reshape(input, [1, ch, h, w])\n",
    "    input = torch.from_numpy(input)\n",
    "    # input = input.cuda(gpu_id)\n",
    "\n",
    "    vgg_model = VGGNet(requires_grad=True)\n",
    "    fcn_model = FCNs(pretrained_net=vgg_model, n_class=n_class)\n",
    "    output, output_2, output_3 = fcn_model(input)\n",
    "    \n",
    "    out = output.data.numpy()\n",
    "    out_2 = output_2.data.numpy()\n",
    "    out_3 = output_3.data.numpy()\n",
    "\n",
    "    h = h - 1\n",
    "    w = w - 1\n",
    "    feat = np.zeros((h, w))\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            feat[i, j] = np.mean(out[0, :, i, j])\n",
    "    \n",
    "    h = out_2.shape[2]\n",
    "    w = out_2.shape[3]    \n",
    "    out2 = np.zeros((h, w))\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            out2[i, j] = np.mean(out_2[0, :, i, j])\n",
    "      \n",
    "    h = out_3.shape[2]\n",
    "    w = out_3.shape[3]    \n",
    "    out3 = np.zeros((h, w))\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            out3[i, j] = np.mean(out_3[0, :, i, j])\n",
    "            \n",
    "    return feat, out2, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================\n",
      "image segmentation method\n",
      "=========================\n",
      "\n",
      "for image segmentation:\n",
      "\n",
      "\n",
      "\n",
      "===============\n",
      "admm algorithms\n",
      "===============\n",
      "\n",
      "A partition method with ADMM method, code by pure python.\n",
      "\n",
      "(60, 40)\n",
      "graph success\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import skimage\n",
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed, mark_boundaries, find_boundaries\n",
    "from skimage.filters import sobel\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from os.path import basename, join, isfile\n",
    "import os\n",
    "import matplotlib.pyplot as plt    \n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from image_segmentation import normal_image_segmentation\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "basename = os.getcwd()\n",
    "img_dir = join(basename, 'input')\n",
    "img_list = [join(img_dir, f) for f in os.listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "\n",
    "def sp_met(img_path, met='watershed', sp_show=True, feat_show=True):\n",
    "    \n",
    "    # VGG feat\n",
    "    #  get conv feature\n",
    "#     img = cv2.imread(img_path)\n",
    "#     conv_1, conv_2 = vgg(img_path)\n",
    "#     conv_1_2 = (conv_1 + conv_2) / 2\n",
    "\n",
    "#     gray_img = skimage.io.imread(img_path, as_gray=True)\n",
    "#     comb = (gray_img + conv_1_2) / 2\n",
    "\n",
    "#     # FCN \n",
    "    #  get conv feature\n",
    "    feat, out2, out3 = fcn(img_path)\n",
    "    return out2, out3\n",
    "\n",
    "\n",
    "#     if feat_show == True:\n",
    "#         # vis feature\n",
    "#         fig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "#         ax[0, 0].imshow(img)\n",
    "#         ax[0, 0].set_title('ori-img')\n",
    "\n",
    "#         ax[0, 1].imshow(conv_1)\n",
    "#         ax[0, 1].set_title('vgg conv_1 feat')\n",
    "\n",
    "#         ax[1, 0].imshow(conv_2)\n",
    "#         ax[1, 0].set_title('vgg conv_2 feat')\n",
    "\n",
    "#         ax[1, 1].imshow(conv_1_2)\n",
    "#         ax[1, 1].set_title('vgg conv (1+2) feat')\n",
    "    \n",
    "        \n",
    "#         fig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "#         ax[0, 0].imshow(img)\n",
    "#         ax[0, 0].set_title('ori-img')\n",
    "\n",
    "#         ax[0, 1].imshow(conv_1, cmap='gray')\n",
    "#         ax[0, 1].set_title('vgg conv_1 feat')\n",
    "\n",
    "#         ax[1, 0].imshow(conv_2, cmap='gray')\n",
    "#         ax[1, 0].set_title('vgg conv_2 feat')\n",
    "\n",
    "#         ax[1, 1].imshow(conv_1_2, cmap='gray')\n",
    "#         ax[1, 1].set_title('vgg conv (1+2) feat')\n",
    "        \n",
    "        \n",
    "#         fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "#         ax[0, 0].imshow(img)\n",
    "#         ax[0, 0].set_title('ori-img')\n",
    "\n",
    "#         ax[0, 1].imshow(feat, cmap='gray')\n",
    "#         ax[0, 1].set_title('fcn feat')\n",
    "\n",
    "#         ax[1, 0].imshow(out2, cmap='gray')\n",
    "#         ax[1, 0].set_title('')\n",
    "\n",
    "#         ax[1, 1].imshow(out3, cmap='gray')\n",
    "#         ax[1, 1].set_title('')\n",
    "        \n",
    "#         plt.show()\n",
    "        \n",
    "#     # generate superpixels\n",
    "#     if met == 'felzenszwalb':\n",
    "#         # 1. use rgb\n",
    "#         segments_rgb = felzenszwalb(img, scale=100, sigma=0.5, min_size=50)\n",
    "#         # 2. use vgg16 conv_1, conv_2, conv_1_2\n",
    "#         segments_conv_1 = felzenszwalb(conv_1, scale=100, sigma=0.5, min_size=50)\n",
    "#         segments_conv_2 = felzenszwalb(conv_2, scale=100, sigma=0.5, min_size=50)\n",
    "#         segments_conv_1_2 = felzenszwalb(conv_1_2, scale=100, sigma=0.5, min_size=50)\n",
    "#         # 3. combined?\n",
    "#         segments_comb = felzenszwalb(comb, scale=100, sigma=0.5, min_size=50)\n",
    "\n",
    "        \n",
    "#     elif met == 'slic':\n",
    "#         # 1. use img\n",
    "#         segments_rgb = slic(img, n_segments=250, compactness=10, sigma=1)\n",
    "#         # 2. use feat_1, feat_2, feat_1_2\n",
    "#         segments_conv_1 = slic(conv_1, n_segments=50, compactness=10, sigma=1)\n",
    "#         segments_conv_2 = slic(conv_2, n_segments=25, compactness=10, sigma=1)\n",
    "#         segments_conv_1_2 = slic(conv_1_2, n_segments=9, compactness=10, sigma=1)\n",
    "#         # 3. combined?\n",
    "#         segments_comb = slic(comb, n_segments=250, compactness=10, sigma=1)\n",
    "\n",
    "        \n",
    "#     elif met == 'quickshift':\n",
    "        \n",
    "#         # 1. use img\n",
    "#         segments_rgb = quickshift(img, kernel_size=3, max_dist=6, ratio=0.5)\n",
    "#         # 2. use feat_1, feat_2, feat_1_2\n",
    "#         segments_conv_1 = quickshift(conv_1, kernel_size=3, max_dist=6, ratio=0.5)\n",
    "#         segments_conv_2 = quickshift(conv_2, kernel_size=3, max_dist=6, ratio=0.5)\n",
    "#         segments_conv_1_2 = quickshift(conv_1_2, kernel_size=3, max_dist=6, ratio=0.5)\n",
    "#         # 3. combined?\n",
    "#         segments_comb = quickshift(comb, kernel_size=3, max_dist=6, ratio=0.5)\n",
    "        \n",
    "        \n",
    "#     elif met == 'watershed':\n",
    "\n",
    "#         # 1. use img\n",
    "#         gradient = sobel(rgb2gray(img))\n",
    "#         segments_rgb = watershed(gradient, markers=250, compactness=0.001)\n",
    "#         # 2. use feat_1, feat_2, feat_1_2\n",
    "#         gradient = sobel(conv_1)\n",
    "#         segments_conv_1 = watershed(gradient, markers=250, compactness=0.001)\n",
    "        \n",
    "#         gradient = sobel(conv_2)\n",
    "#         segments_conv_2 = watershed(gradient, markers=250, compactness=0.001)\n",
    "        \n",
    "#         gradient = sobel(conv_1_2)\n",
    "#         segments_conv_1_2 = watershed(gradient, markers=250, compactness=0.001)\n",
    "        \n",
    "#         # 3. combined?\n",
    "#         gradient = sobel(comb)\n",
    "#         segments_comb = watershed(gradient, markers=250, compactness=0.001)\n",
    "        \n",
    "#     else:\n",
    "#         print('superpixels method need')\n",
    "        \n",
    "#     if sp_show == True:\n",
    "#         # show superpixels results\n",
    "#         fig, ax = plt.subplots(3, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "#         # superpixel vis\n",
    "#         ax[0, 0].imshow(img)\n",
    "#         ax[0, 0].set_title('ori-img')\n",
    "\n",
    "#         ax[0, 1].imshow(mark_boundaries(img, segments_conv_1))\n",
    "#         ax[0, 1].set_title('conv_1_feat')\n",
    "\n",
    "#         ax[1, 0].imshow(mark_boundaries(img, segments_conv_2))\n",
    "#         ax[1, 0].set_title('conv_2_feat')\n",
    "\n",
    "#         ax[1, 1].imshow(mark_boundaries(img, segments_conv_1_2))\n",
    "#         ax[1, 1].set_title('conv_1_2_feat')\n",
    "\n",
    "#         ax[2, 0].imshow(mark_boundaries(img, segments_rgb))\n",
    "#         ax[2, 0].set_title('rgb_feat')\n",
    "\n",
    "#         ax[2, 1].imshow(mark_boundaries(img, segments_comb))\n",
    "#         ax[2, 1].set_title('comb_feat')\n",
    "#         plt.show()\n",
    "\n",
    "        \n",
    "# vis part\n",
    "for img_path in img_list:\n",
    "    \n",
    "    if img_path[-3:] == 'jpg':\n",
    "#         out2, out3 = sp_met(img_path=img_path)\n",
    "        feat, out2, out3 = fcn(img_path)\n",
    "#         print(out2.shape)\n",
    "#         print(out3.shape)\n",
    "        \n",
    "#         for k in [2, 5, 8]:\n",
    "        # add our method\n",
    "        segments = normal_image_segmentation(m_img=out2, graph_met='syn_met', num_cuts=2)\n",
    "    #         plt.figure()\n",
    "    #         plt.imshow(segments)\n",
    "    #         plt.show()\n",
    "\n",
    "\n",
    "        # plot segments in different paras\n",
    "        plt.figure()\n",
    "        bounder = find_boundaries(segments, mode='thick').astype(np.uint8)\n",
    "        plt.imshow(bounder, cmap='gray')\n",
    "\n",
    "    #         plt.figure()\n",
    "    #         plt.imshow(mark_boundaries(out3, segments))\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "#         # weight of rgb and conv feat \n",
    "#         weight = [0.01, 0.1, 1, 10, 100]\n",
    "#         fig, ax = plt.subplots(3, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "#         for i, w in enumerate(weight):\n",
    "#             comb = (w * gray_img + conv_1_2) / (w + 1)\n",
    "#             segments_comb = felzenszwalb(comb, scale=100, sigma=0.5, min_size=50)\n",
    "\n",
    "#             ax[int(i-i%2)/2, int(i%2)].imshow(mark_boundaries(img, segments_comb))\n",
    "# #             ax[int(i-i%2)/2, int(i%2)].set_title('Subplot n°{}' .format(i+1))\n",
    "\n",
    "#         fig.delaxes(ax[2, 1])\n",
    "#         plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add our method\n",
    "m_img = np.asarray([[1,2],[3,4]])\n",
    "len(m_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35049\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed, mark_boundaries\n",
    "from os.path import join, isfile\n",
    "import os\n",
    "import cv2\n",
    "from skimage.filters import sobel\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# ASA, BR evaluate\n",
    "\n",
    "# by different sp numbers(given different paras here)\n",
    "\n",
    "para_list = [0.1, 1, 10, 50, 100, 200]\n",
    "# para_list = [1, 2, 5, 8, 10]\n",
    "# para_list = [0.001, 0.005, 0.01]\n",
    "\n",
    "# gtseg_dir = '../SEAL/data/groundtruth'\n",
    "# label_dir = '../SEAL/data/output/500'\n",
    "\n",
    "basename = os.getcwd()\n",
    "img_dir = join(basename, 'input')\n",
    "img_list = [join(img_dir, f) for f in os.listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "\n",
    "img_dir = './output'\n",
    "# prepare output folders\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "\n",
    "\n",
    "label_dir = []\n",
    "for met in ['rgb', 'vgg_conv', 'vgg_comb', 'fcn_conv', 'fcn_comb']:\n",
    "    feat_dir = join(img_dir, met)\n",
    "    if not os.path.exists(feat_dir):\n",
    "        os.makedirs(feat_dir)\n",
    "\n",
    "    for para in para_list:\n",
    "        para_dir = os.path.join(feat_dir, str(para))\n",
    "        if not os.path.exists(para_dir):\n",
    "            os.makedirs(para_dir)\n",
    "\n",
    "        \n",
    "# save sp results\n",
    "for img_path in img_list:\n",
    "    if img_path[-3:] == 'jpg':\n",
    "        img_name = img_path.split('/')[-1].split('.')[0]\n",
    "        print(img_name)\n",
    "        \n",
    "        #  get feature: rgb, vgg_conv, vgg_comb, fcn_conv, fcn_comb\n",
    "        rgb = cv2.imread(img_path)\n",
    "        gray_img = skimage.io.imread(img_path, as_gray=True)\n",
    "\n",
    "        conv_1, conv_2 = vgg(img_path)\n",
    "        vgg_conv = (conv_1 + conv_2) / 2\n",
    "        vgg_comb = (gray_img + vgg_conv) / 2\n",
    "        \n",
    "#         fcn_conv = fcn(img_path)        \n",
    "#         fcn_comb = (gray_img + fcn_conv) / 2\n",
    "        \n",
    "        # 与图片最后一行与最后一列拼接（更好的方法？）        \n",
    "        conv_ = fcn(img_path)\n",
    "        fcn_conv = np.resize(conv_, (gray_img.shape))\n",
    "        fcn_comb = (gray_img + fcn_conv) / 2\n",
    "        \n",
    "        for para in para_list:\n",
    "            for feat, feat_dir in zip([rgb, vgg_conv, vgg_comb, fcn_conv, fcn_comb], \\\n",
    "                                      ['rgb', 'vgg_conv', 'vgg_comb', 'fcn_conv', 'fcn_comb']):         \n",
    "\n",
    "                # save segmnets labels as uint16 png files\n",
    "                segments = felzenszwalb(feat, scale=para, sigma=0.5, min_size=50)\n",
    "#                 segments = quickshift(feat, kernel_size=3, max_dist=para, ratio=0.5)\n",
    "#                 gradient = sobel(rgb2gray(feat))\n",
    "#                 segments = watershed(gradient, markers=250, compactness=para)\n",
    "        \n",
    "                output_fullpath = os.path.join('./output', feat_dir, str(para), img_name + '.png')\n",
    "                cv2.imwrite(output_fullpath, np.uint16(segments))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, '../SEAL/eval')\n",
    "from eval import evaluate\n",
    "import os\n",
    "import matplotlib.pyplot as plt    \n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "# compute asa, br\n",
    "# by rgb, conv, comb\n",
    "\n",
    "asa_list, br_list = [], []\n",
    "gtseg_dir = './groundtruth'\n",
    "\n",
    "for feat, feat_dir in zip([rgb, vgg_conv, vgg_comb, fcn_conv, fcn_comb], \\\n",
    "                          ['rgb', 'vgg_conv', 'vgg_comb', 'fcn_conv', 'fcn_comb']):       \n",
    "    feat_asa, feat_br = [], []\n",
    "    for para in para_list:\n",
    "\n",
    "        label_dir = os.path.join('./output', feat_dir, str(para))\n",
    "        asa, br = evaluate(gtseg_dir, label_dir)\n",
    "        feat_asa.append(asa) \n",
    "        feat_br.append(br)\n",
    "        \n",
    "    asa_list.append(feat_asa)\n",
    "    br_list.append(feat_br)\n",
    "    \n",
    "\n",
    "# plot asa & br curves\n",
    "labels = ['rgb', 'vgg_conv', 'vgg_comb', 'fcn_conv', 'fcn_comb']\n",
    "\n",
    "plt.figure('ASA')\n",
    "for asa_, label in zip(asa_list, labels):\n",
    "    plt.plot(para_list, asa_, label=label)\n",
    "    plt.scatter(para_list, asa_)\n",
    "\n",
    "plt.xlabel('superpixels para')\n",
    "plt.ylabel('ASA (Achievable Segmentation Accuracy)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.figure('BR')\n",
    "for br_, label in zip(br_list, labels):\n",
    "    plt.plot(para_list, br_, label=label)\n",
    "    plt.scatter(para_list, br_)\n",
    "\n",
    "plt.xlabel('superpixels para')\n",
    "plt.ylabel('BR (Boundary Recall)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, io, segmentation, color\n",
    "\n",
    "out = color.label2rgb(labels2, img, kind='avg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PAN]",
   "language": "python",
   "name": "conda-env-PAN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
